//
//  SmartImageCropper.swift
//  Weeks
//
//  Created by AI Assistant on 7/4/25.
//

import UIKit
import Vision

/// æ™ºèƒ½å›¾ç‰‡è£å‰ªå™¨ï¼Œä½¿ç”¨Visionæ¡†æ¶çš„æ˜¾è‘—æ€§æ£€æµ‹æŠ€æœ¯
struct SmartImageCropper {
    
    /// è£å‰ªç­–ç•¥æšä¸¾
    enum CropStrategy {
        case center          // ä¼ ç»Ÿä¸­å¿ƒè£å‰ª
        case attentionBased  // åŸºäºæ³¨æ„åŠ›çš„æ˜¾è‘—æ€§æ£€æµ‹ï¼ˆè§†è§‰ç„¦ç‚¹ï¼‰
        case objectBased     // åŸºäºå¯¹è±¡çš„æ˜¾è‘—æ€§æ£€æµ‹ï¼ˆå‰æ™¯ç‰©ä½“ï¼‰
        case faceDetection   // äººè„¸æ£€æµ‹ï¼ˆç²¾ç¡®å®šä½ï¼‰
        case hybrid          // æ··åˆç­–ç•¥ï¼ˆåŸºäºVisionæ¡†æ¶ç‰¹æ€§çš„ä¼˜åŒ–ç»„åˆï¼‰
    }
    
    /// æ˜¾è‘—åŒºåŸŸä½ç½®ç±»å‹
    private enum SalientPosition {
        case center       // ä¸­å¿ƒåŒºåŸŸ
        case leftEdge     // å·¦è¾¹ç¼˜
        case rightEdge    // å³è¾¹ç¼˜
        case topEdge      // ä¸Šè¾¹ç¼˜
        case bottomEdge   // ä¸‹è¾¹ç¼˜
        case topLeft      // å·¦ä¸Šè§’
        case topRight     // å³ä¸Šè§’
        case bottomLeft   // å·¦ä¸‹è§’
        case bottomRight  // å³ä¸‹è§’
    }
    
    /// æ‰©å±•å‘é‡ç»“æ„ä½“
    private struct ExpansionVector {
        let left: CGFloat     // å·¦ä¾§æ‰©å±•å› å­
        let right: CGFloat    // å³ä¾§æ‰©å±•å› å­
        let top: CGFloat      // ä¸Šä¾§æ‰©å±•å› å­
        let bottom: CGFloat   // ä¸‹ä¾§æ‰©å±•å› å­
    }
    
    /// æ™ºèƒ½è£å‰ªå›¾ç‰‡åˆ°æŒ‡å®šå®½é«˜æ¯”
    /// - Parameters:
    ///   - image: åŸå§‹å›¾ç‰‡
    ///   - targetRatio: ç›®æ ‡å®½é«˜æ¯”
    ///   - strategy: è£å‰ªç­–ç•¥
    ///   - completion: å®Œæˆå›è°ƒ
    static func smartCrop(
        image: UIImage,
        toAspectRatio targetRatio: CGFloat,
        strategy: CropStrategy = .hybrid,
        completion: @escaping (UIImage?) -> Void
    ) {
        // æ·»åŠ å…¨å±€è¶…æ—¶ä¿æŠ¤
        var hasCompleted = false
        let timeoutSeconds = 8.0 // 8ç§’è¶…æ—¶
        
        // åˆ›å»ºå®‰å…¨å›è°ƒå‡½æ•°ï¼Œç¡®ä¿åªè°ƒç”¨ä¸€æ¬¡
        let safeCompletion: (UIImage?) -> Void = { result in
            DispatchQueue.main.async {
                if !hasCompleted {
                    hasCompleted = true
                    completion(result)
                }
            }
        }
        
        // è®¾ç½®å…¨å±€è¶…æ—¶
        DispatchQueue.global().asyncAfter(deadline: .now() + timeoutSeconds) {
            if !hasCompleted {
                print("æ™ºèƒ½è£å‰ªè¶…æ—¶ï¼Œä½¿ç”¨ä¸­å¿ƒè£å‰ªä½œä¸ºå…œåº•")
                let centerResult = ImageCropper.cropCenter(of: image, toAspectRatio: targetRatio)
                safeCompletion(centerResult)
            }
        }
        
        switch strategy {
        case .center:
            let result = ImageCropper.cropCenter(of: image, toAspectRatio: targetRatio)
            safeCompletion(result)
            
        case .attentionBased:
            print("ä½¿ç”¨æ³¨æ„åŠ›æ˜¾è‘—æ€§è£å‰ªç­–ç•¥")
            cropUsingAttentionSaliency(image: image, targetRatio: targetRatio) { result in
                safeCompletion(result)
            }
            
        case .objectBased:
            print("ä½¿ç”¨å¯¹è±¡æ˜¾è‘—æ€§è£å‰ªç­–ç•¥")
            cropUsingObjectSaliency(image: image, targetRatio: targetRatio) { result in
                safeCompletion(result)
            }
            
        case .faceDetection:
            print("ä½¿ç”¨äººè„¸æ£€æµ‹è£å‰ªç­–ç•¥")
            cropUsingFaceDetection(image: image, targetRatio: targetRatio) { result in
                safeCompletion(result)
            }
            
        case .hybrid:
            print("ä½¿ç”¨æ··åˆè£å‰ªç­–ç•¥")
            // åŸºäºApple Visionæ¡†æ¶ç‰¹æ€§çš„ä¼˜åŒ–ç­–ç•¥ï¼š
            // 1. äººè„¸æ£€æµ‹ï¼ˆç²¾ç¡®å®šä½ï¼‰
            // 2. å¯¹è±¡æ˜¾è‘—æ€§ï¼ˆå‰æ™¯ç‰©ä½“ï¼‰
            // 3. æ³¨æ„åŠ›æ˜¾è‘—æ€§ï¼ˆè§†è§‰ç„¦ç‚¹ï¼‰
            // 4. ä¸­å¿ƒè£å‰ªï¼ˆå…œåº•ï¼‰
            
            // ä¸ºæ¯ä¸ªæ­¥éª¤è®¾ç½®å•ç‹¬çš„è¶…æ—¶
            let stepTimeoutSeconds = 2.5 // æ¯ä¸ªæ­¥éª¤2.5ç§’è¶…æ—¶
            
            // æ­¥éª¤1ï¼šäººè„¸æ£€æµ‹
            let faceDetectionTimeout = DispatchWorkItem {
                if !hasCompleted {
                    print("äººè„¸æ£€æµ‹è¶…æ—¶ï¼Œå°è¯•å¯¹è±¡æ˜¾è‘—æ€§")
                    // æ­¥éª¤2ï¼šå¯¹è±¡æ˜¾è‘—æ€§
                    cropUsingObjectSaliency(image: image, targetRatio: targetRatio) { objectResult in
                        if !hasCompleted && objectResult != nil {
                            print("å¯¹è±¡æ˜¾è‘—æ€§æ£€æµ‹æˆåŠŸ")
                            safeCompletion(objectResult)
                        } else if !hasCompleted {
                            print("å¯¹è±¡æ˜¾è‘—æ€§æ£€æµ‹å¤±è´¥ï¼Œå°è¯•æ³¨æ„åŠ›æ˜¾è‘—æ€§")
                            // æ­¥éª¤3ï¼šæ³¨æ„åŠ›æ˜¾è‘—æ€§
                            cropUsingAttentionSaliency(image: image, targetRatio: targetRatio) { attentionResult in
                                if !hasCompleted && attentionResult != nil {
                                    print("æ³¨æ„åŠ›æ˜¾è‘—æ€§æ£€æµ‹æˆåŠŸ")
                                    safeCompletion(attentionResult)
                                } else if !hasCompleted {
                                    print("æ³¨æ„åŠ›æ˜¾è‘—æ€§æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ä¸­å¿ƒè£å‰ª")
                                    // æ­¥éª¤4ï¼šä¸­å¿ƒè£å‰ªï¼ˆå…œåº•ï¼‰
                                    let centerResult = ImageCropper.cropCenter(of: image, toAspectRatio: targetRatio)
                                    safeCompletion(centerResult)
                                }
                            }
                        }
                    }
                }
            }
            
            // å¼€å§‹äººè„¸æ£€æµ‹
            cropUsingFaceDetection(image: image, targetRatio: targetRatio) { result in
                // å–æ¶ˆè¶…æ—¶ä»»åŠ¡
                faceDetectionTimeout.cancel()
                
                if !hasCompleted && result != nil {
                    print("äººè„¸æ£€æµ‹æˆåŠŸ")
                    safeCompletion(result)
                } else if !hasCompleted {
                    print("äººè„¸æ£€æµ‹å¤±è´¥ï¼Œå°è¯•å¯¹è±¡æ˜¾è‘—æ€§")
                    // æ­¥éª¤2ï¼šå¯¹è±¡æ˜¾è‘—æ€§
                    cropUsingObjectSaliency(image: image, targetRatio: targetRatio) { objectResult in
                        if !hasCompleted && objectResult != nil {
                            print("å¯¹è±¡æ˜¾è‘—æ€§æ£€æµ‹æˆåŠŸ")
                            safeCompletion(objectResult)
                        } else if !hasCompleted {
                            print("å¯¹è±¡æ˜¾è‘—æ€§æ£€æµ‹å¤±è´¥ï¼Œå°è¯•æ³¨æ„åŠ›æ˜¾è‘—æ€§")
                            // æ­¥éª¤3ï¼šæ³¨æ„åŠ›æ˜¾è‘—æ€§
                            cropUsingAttentionSaliency(image: image, targetRatio: targetRatio) { attentionResult in
                                if !hasCompleted && attentionResult != nil {
                                    print("æ³¨æ„åŠ›æ˜¾è‘—æ€§æ£€æµ‹æˆåŠŸ")
                                    safeCompletion(attentionResult)
                                } else if !hasCompleted {
                                    print("æ³¨æ„åŠ›æ˜¾è‘—æ€§æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ä¸­å¿ƒè£å‰ª")
                                    // æ­¥éª¤4ï¼šä¸­å¿ƒè£å‰ªï¼ˆå…œåº•ï¼‰
                                    let centerResult = ImageCropper.cropCenter(of: image, toAspectRatio: targetRatio)
                                    safeCompletion(centerResult)
                                }
                            }
                        }
                    }
                }
            }
            
            // è®¾ç½®äººè„¸æ£€æµ‹è¶…æ—¶
            DispatchQueue.global().asyncAfter(deadline: .now() + stepTimeoutSeconds, execute: faceDetectionTimeout)
        }
    }
    
    /// æ ¹æ®Widgetå°ºå¯¸ç±»å‹æ™ºèƒ½è£å‰ªå›¾ç‰‡
    static func smartCrop(
        image: UIImage,
        for sizeType: WidgetSizeType,
        strategy: CropStrategy = .hybrid,
        completion: @escaping (UIImage?) -> Void
    ) {
        let targetRatio = ImageCropper.aspectRatio(for: sizeType)
        smartCrop(image: image, toAspectRatio: targetRatio, strategy: strategy, completion: completion)
    }
    
    // MARK: - å›¾ç‰‡é¢„å¤„ç†
    
    /// é¢„å¤„ç†å›¾ç‰‡ï¼šç¼©æ”¾åˆ°åˆé€‚å°ºå¯¸ä»¥æé«˜æ£€æµ‹æ•ˆç‡å’Œæœ€ç»ˆè´¨é‡
    private static func preprocessImageForDetection(_ image: UIImage) -> UIImage {
        let currentSize = image.size
        let currentScale = image.scale
        let actualPixelArea = currentSize.width * currentScale * currentSize.height * currentScale
        
        // è®¾å®šæ£€æµ‹ç”¨çš„æœ€ä½³åƒç´ é¢ç§¯ï¼ˆ2000x2000å·¦å³ï¼Œæ—¢ä¿è¯æ£€æµ‹ç²¾åº¦åˆä¸ä¼šå¤ªå¤§ï¼‰
        let optimalDetectionArea: CGFloat = 4000000 // ~2000x2000
        
        if actualPixelArea <= optimalDetectionArea {
            print("ğŸ“ é¢„å¤„ç†: å›¾ç‰‡å°ºå¯¸åˆé€‚ï¼Œæ— éœ€ç¼©æ”¾")
            return image
        }
        
        let scaleFactor = sqrt(optimalDetectionArea / actualPixelArea)
        let newSize = CGSize(
            width: currentSize.width * scaleFactor,
            height: currentSize.height * scaleFactor
        )
        
        print("ğŸ“ é¢„å¤„ç†: ç¼©æ”¾å›¾ç‰‡ç”¨äºæ£€æµ‹")
        print("   åŸå§‹å°ºå¯¸: \(currentSize)")
        print("   æ£€æµ‹å°ºå¯¸: \(newSize)")
        print("   ç¼©æ”¾å› å­: \(scaleFactor)")
        
        UIGraphicsBeginImageContextWithOptions(newSize, false, 1.0)
        defer { UIGraphicsEndImageContext() }
        
        image.draw(in: CGRect(origin: .zero, size: newSize))
        
        guard let preprocessedImage = UIGraphicsGetImageFromCurrentImageContext() else {
            print("ğŸ“ é¢„å¤„ç†: ç¼©æ”¾å¤±è´¥ï¼Œä½¿ç”¨åŸå›¾")
            return image
        }
        
        return preprocessedImage
    }
    
    // MARK: - åŸºäºæ³¨æ„åŠ›çš„æ˜¾è‘—æ€§æ£€æµ‹è£å‰ª
    
    private static func cropUsingAttentionSaliency(
        image: UIImage,
        targetRatio: CGFloat,
        completion: @escaping (UIImage?) -> Void
    ) {
        // é¢„å¤„ç†å›¾ç‰‡ä»¥æé«˜æ£€æµ‹æ•ˆç‡
        let processedImage = preprocessImageForDetection(image)
        
        guard let cgImage = processedImage.cgImage else {
            print("ğŸ” SmartCropper: æ— æ³•è·å–CGImageï¼Œå›é€€åˆ°ä¸­å¿ƒè£å‰ª")
            completion(nil)
            return
        }
        
        print("ğŸ§  SmartCropper: å¼€å§‹æ³¨æ„åŠ›æ˜¾è‘—æ€§æ£€æµ‹")
        
        let request = VNGenerateAttentionBasedSaliencyImageRequest { request, error in
            DispatchQueue.main.async {
                if let error = error {
                    print("ğŸ” SmartCropper: æ³¨æ„åŠ›æ£€æµ‹å¤±è´¥ - \(error.localizedDescription)")
                    completion(nil)
                    return
                }
                
                guard let results = request.results as? [VNSaliencyImageObservation],
                      let observation = results.first else {
                    print("ğŸ” SmartCropper: æ³¨æ„åŠ›æ£€æµ‹æ— ç»“æœ")
                    completion(nil)
                    return
                }
                
                let croppedImage = cropImageUsingSaliency(
                    originalImage: image,
                    processedImage: processedImage,
                    observation: observation,
                    targetRatio: targetRatio,
                    saliencyType: "æ³¨æ„åŠ›"
                )
                
                completion(croppedImage)
            }
        }
        
        let requestHandler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        
        DispatchQueue.global(qos: .userInitiated).async {
            do {
                try requestHandler.perform([request])
            } catch {
                print("ğŸ” SmartCropper: æ³¨æ„åŠ›æ£€æµ‹æ‰§è¡Œå¤±è´¥ - \(error.localizedDescription)")
                DispatchQueue.main.async {
                    completion(nil)
                }
            }
        }
    }
    
    // MARK: - äººè„¸æ£€æµ‹è£å‰ªï¼ˆä¸“æ³¨äºäººè„¸ï¼Œç§»é™¤æœ‰é—®é¢˜çš„åŠ¨ç‰©æ£€æµ‹ï¼‰
    
    private static func cropUsingFaceDetection(
        image: UIImage,
        targetRatio: CGFloat,
        completion: @escaping (UIImage?) -> Void
    ) {
        // é¢„å¤„ç†å›¾ç‰‡ä»¥æé«˜æ£€æµ‹æ•ˆç‡
        let processedImage = preprocessImageForDetection(image)
        
        guard let cgImage = processedImage.cgImage else {
            print("ğŸ” SmartCropper: æ— æ³•è·å–CGImage")
            completion(nil)
            return
        }
        
        print("ğŸ‘¤ SmartCropper: å¼€å§‹äººè„¸æ£€æµ‹")
        
        // åªè¿›è¡Œäººè„¸æ£€æµ‹ï¼Œä½¿ç”¨æ›´ç²¾ç¡®çš„äººè„¸æ£€æµ‹è¯·æ±‚
        let faceRequest = VNDetectFaceRectanglesRequest()
        faceRequest.revision = VNDetectFaceRectanglesRequestRevision3 // ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬
        
        let requestHandler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        
        DispatchQueue.global(qos: .userInitiated).async {
            do {
                try requestHandler.perform([faceRequest])
                
                DispatchQueue.main.async {
                    let faceResults = faceRequest.results ?? []
                    
                    if let croppedImage = processFaceDetectionResults(
                        originalImage: image,
                        processedImage: processedImage,
                        faceResults: faceResults,
                        targetRatio: targetRatio
                    ) {
                        completion(croppedImage)
                    } else {
                        print("ğŸ‘¤ SmartCropper: æœªæ£€æµ‹åˆ°äººè„¸")
                        completion(nil)
                    }
                }
            } catch {
                print("ğŸ‘¤ SmartCropper: äººè„¸æ£€æµ‹æ‰§è¡Œå¤±è´¥ - \(error.localizedDescription)")
                DispatchQueue.main.async {
                    completion(nil)
                }
            }
        }
    }
    
    // MARK: - åŸºäºå¯¹è±¡çš„æ˜¾è‘—æ€§æ£€æµ‹è£å‰ª
    
    private static func cropUsingObjectSaliency(
        image: UIImage,
        targetRatio: CGFloat,
        completion: @escaping (UIImage?) -> Void
    ) {
        // é¢„å¤„ç†å›¾ç‰‡ä»¥æé«˜æ£€æµ‹æ•ˆç‡
        let processedImage = preprocessImageForDetection(image)
        
        guard let cgImage = processedImage.cgImage else {
            print("ğŸ” SmartCropper: æ— æ³•è·å–CGImageï¼Œå›é€€åˆ°ä¸­å¿ƒè£å‰ª")
            completion(nil)
            return
        }
        
        print("ğŸ¯ SmartCropper: å¼€å§‹å¯¹è±¡æ˜¾è‘—æ€§æ£€æµ‹")
        
        let request = VNGenerateObjectnessBasedSaliencyImageRequest { request, error in
            DispatchQueue.main.async {
                if let error = error {
                    print("ğŸ” SmartCropper: å¯¹è±¡æ£€æµ‹å¤±è´¥ - \(error.localizedDescription)")
                    completion(nil)
                    return
                }
                
                guard let results = request.results as? [VNSaliencyImageObservation],
                      let observation = results.first else {
                    print("ğŸ” SmartCropper: å¯¹è±¡æ£€æµ‹æ— ç»“æœ")
                    completion(nil)
                    return
                }
                
                let croppedImage = cropImageUsingSaliency(
                    originalImage: image,
                    processedImage: processedImage,
                    observation: observation,
                    targetRatio: targetRatio,
                    saliencyType: "å¯¹è±¡"
                )
                
                completion(croppedImage)
            }
        }
        
        let requestHandler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        
        DispatchQueue.global(qos: .userInitiated).async {
            do {
                try requestHandler.perform([request])
            } catch {
                print("ğŸ” SmartCropper: å¯¹è±¡æ£€æµ‹æ‰§è¡Œå¤±è´¥ - \(error.localizedDescription)")
                DispatchQueue.main.async {
                    completion(nil)
                }
            }
        }
    }
    
    // MARK: - äººè„¸æ£€æµ‹ç»“æœå¤„ç†
    
    /// å¤„ç†äººè„¸æ£€æµ‹ç»“æœï¼ˆä¸“æ³¨äºäººè„¸ï¼Œæé«˜ç²¾ç¡®æ€§ï¼‰
    private static func processFaceDetectionResults(
        originalImage: UIImage,
        processedImage: UIImage,
        faceResults: [VNFaceObservation],
        targetRatio: CGFloat
    ) -> UIImage? {
        guard !faceResults.isEmpty else {
            return nil
        }
        
        let originalSize = originalImage.size
        let processedSize = processedImage.size
        print("ğŸ‘¤ SmartCropper: å¤„ç†äººè„¸æ£€æµ‹ç»“æœ")
        print("   æ£€æµ‹åˆ° \(faceResults.count) ä¸ªäººè„¸")
        print("   åŸå§‹å›¾ç‰‡å°ºå¯¸: \(originalSize)")
        print("   é¢„å¤„ç†å›¾ç‰‡å°ºå¯¸: \(processedSize)")
        
        // è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œç”¨äºå°†é¢„å¤„ç†å›¾ç‰‡çš„åæ ‡æ˜ å°„å›åŸå›¾
        let scaleX = originalSize.width / processedSize.width
        let scaleY = originalSize.height / processedSize.height
        
        // ç­›é€‰é«˜ç½®ä¿¡åº¦çš„äººè„¸ï¼ˆæé«˜ç²¾ç¡®æ€§ï¼‰
        let highConfidenceFaces = faceResults.filter { $0.confidence > 0.5 }
        guard !highConfidenceFaces.isEmpty else {
            print("   æ‰€æœ‰äººè„¸ç½®ä¿¡åº¦è¿‡ä½ï¼Œè·³è¿‡äººè„¸æ£€æµ‹")
            return nil
        }
        
        let detectedRect: CGRect
        
        if highConfidenceFaces.count == 1 {
            let face = highConfidenceFaces[0]
            print("   å•ä¸ªé«˜ç½®ä¿¡åº¦äººè„¸ï¼Œç½®ä¿¡åº¦: \(face.confidence)")
            // å…ˆè½¬æ¢åˆ°é¢„å¤„ç†å›¾ç‰‡åæ ‡ç³»ï¼Œå†æ˜ å°„åˆ°åŸå›¾åæ ‡ç³»
            let processedRect = convertVisionRectToUIKit(face.boundingBox, imageSize: processedSize)
            detectedRect = CGRect(
                x: processedRect.origin.x * scaleX,
                y: processedRect.origin.y * scaleY,
                width: processedRect.width * scaleX,
                height: processedRect.height * scaleY
            )
        } else {
            // å¤šä¸ªäººè„¸ï¼šé€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„æˆ–åˆå¹¶ç›¸è¿‘çš„äººè„¸
            print("   å¤šä¸ªé«˜ç½®ä¿¡åº¦äººè„¸ï¼Œæ™ºèƒ½åˆå¹¶å¤„ç†")
            let bestFace = highConfidenceFaces.max { $0.confidence < $1.confidence }!
            
            // æ£€æŸ¥æ˜¯å¦æœ‰ç›¸è¿‘çš„äººè„¸éœ€è¦åˆå¹¶
            var unionRect = bestFace.boundingBox
            for face in highConfidenceFaces {
                if face != bestFace {
                    let distance = sqrt(pow(face.boundingBox.midX - bestFace.boundingBox.midX, 2) + 
                                      pow(face.boundingBox.midY - bestFace.boundingBox.midY, 2))
                    // å¦‚æœäººè„¸è·ç¦»è¾ƒè¿‘ï¼Œåˆå¹¶è¾¹ç•Œæ¡†
                    if distance < 0.3 {
                        unionRect = unionRect.union(face.boundingBox)
                        print("     åˆå¹¶ç›¸è¿‘äººè„¸ï¼Œç½®ä¿¡åº¦: \(face.confidence)")
                    }
                }
            }
            
            // å…ˆè½¬æ¢åˆ°é¢„å¤„ç†å›¾ç‰‡åæ ‡ç³»ï¼Œå†æ˜ å°„åˆ°åŸå›¾åæ ‡ç³»
            let processedUnionRect = convertVisionRectToUIKit(unionRect, imageSize: processedSize)
            detectedRect = CGRect(
                x: processedUnionRect.origin.x * scaleX,
                y: processedUnionRect.origin.y * scaleY,
                width: processedUnionRect.width * scaleX,
                height: processedUnionRect.height * scaleY
            )
        }
        
        print("   äººè„¸æ£€æµ‹åŒºåŸŸ: \(detectedRect)")
        
        // ä½¿ç”¨ä¸“é—¨çš„äººè„¸æ‰©å±•ç®—æ³•
        let expandedRect = expandFaceRect(detectedRect, in: originalSize, targetRatio: targetRatio, type: "äººè„¸")
        print("   æ‰©å±•ååŒºåŸŸ: \(expandedRect)")
        
        // æ ¹æ®ç›®æ ‡å®½é«˜æ¯”è°ƒæ•´è£å‰ªåŒºåŸŸ
        let finalCropRect = adjustRectForAspectRatio(expandedRect, targetRatio: targetRatio, imageSize: originalSize)
        print("   æœ€ç»ˆè£å‰ªåŒºåŸŸ: \(finalCropRect)")
        
        // æ‰§è¡Œè£å‰ªï¼ˆåŸºäºåŸå›¾ï¼‰
        guard let cgImage = originalImage.cgImage?.cropping(to: finalCropRect) else {
            print("   âŒ è£å‰ªå¤±è´¥")
            return nil
        }
        
        let croppedImage = UIImage(cgImage: cgImage, scale: originalImage.scale, orientation: originalImage.imageOrientation)
        print("   âœ… äººè„¸ä¼˜åŒ–è£å‰ªæˆåŠŸ")
        print("   è£å‰ªåå°ºå¯¸: \(croppedImage.size)")
        
        // åº”ç”¨Widgetå°ºå¯¸é™åˆ¶
        return ImageCropper.resizeForWidget(croppedImage, targetRatio: targetRatio)
    }
    

    
    /// å°†Visionåæ ‡ç³»è½¬æ¢ä¸ºUIKitåæ ‡ç³»
    private static func convertVisionRectToUIKit(_ visionRect: CGRect, imageSize: CGSize) -> CGRect {
        return CGRect(
            x: visionRect.origin.x * imageSize.width,
            y: (1 - visionRect.origin.y - visionRect.height) * imageSize.height,
            width: visionRect.width * imageSize.width,
            height: visionRect.height * imageSize.height
        )
    }
    
    /// ä¸“é—¨é’ˆå¯¹äººè„¸çš„æ™ºèƒ½æ‰©å±•ç®—æ³•
    private static func expandFaceRect(
        _ rect: CGRect,
        in imageSize: CGSize,
        targetRatio: CGFloat,
        type: String
    ) -> CGRect {
        print("   å¼€å§‹\(type)ä¸“ç”¨æ‰©å±•ç®—æ³•")
        
        // äººè„¸ç‰¹å®šçš„æ‰©å±•ç­–ç•¥
        let faceAreaRatio = (rect.width * rect.height) / (imageSize.width * imageSize.height)
        
        // æ ¹æ®äººè„¸å¤§å°è°ƒæ•´æ‰©å±•å› å­
        let expansionFactor: CGFloat
        switch faceAreaRatio {
        case 0.3...1.0:   // å¤§äººè„¸ï¼ˆ30%ä»¥ä¸Šï¼‰
            expansionFactor = 1.1   // è½»å¾®æ‰©å±•ï¼Œä¿æŒç„¦ç‚¹
        case 0.1...0.3:   // ä¸­ç­‰äººè„¸ï¼ˆ10%-30%ï¼‰
            expansionFactor = 1.3   // é€‚åº¦æ‰©å±•ï¼ŒåŒ…å«è‚©è†€/èº«ä½“
        case 0.05...0.1:  // å°äººè„¸ï¼ˆ5%-10%ï¼‰
            expansionFactor = 1.6   // è¾ƒå¤šæ‰©å±•ï¼ŒåŒ…å«æ›´å¤šä¸Šä¸‹æ–‡
        default:          // å¾ˆå°çš„äººè„¸ï¼ˆ<5%ï¼‰
            expansionFactor = 2.0   // å¤§é‡æ‰©å±•ï¼Œç¡®ä¿å¯è§æ€§
        }
        
        // äººè„¸çš„ä½ç½®æ„ŸçŸ¥æ‰©å±•
        let position = analyzeFacePosition(rect, in: imageSize)
        let expansionVector = calculateFaceExpansionVector(
            position: position,
            rect: rect,
            imageSize: imageSize,
            targetRatio: targetRatio,
            baseFactor: expansionFactor,
            type: type
        )
        
        return applyExpansionWithBounds(
            rect: rect,
            expansionVector: expansionVector,
            imageSize: imageSize
        )
    }
    
    /// åˆ†æäººè„¸åœ¨å›¾ç‰‡ä¸­çš„ä½ç½®
    private static func analyzeFacePosition(_ rect: CGRect, in imageSize: CGSize) -> SalientPosition {
        let rectCenterY = rect.midY
        let imageHeight = imageSize.height
        
        // å¯¹äºäººè„¸ï¼Œæ›´å…³æ³¨å‚ç›´ä½ç½®
        if rectCenterY < imageHeight * 0.25 {
            return .topEdge      // é¡¶éƒ¨åŒºåŸŸï¼ˆå¯èƒ½éœ€è¦å‘ä¸‹æ‰©å±•æ›´å¤šï¼‰
        } else if rectCenterY > imageHeight * 0.75 {
            return .bottomEdge   // åº•éƒ¨åŒºåŸŸï¼ˆå¯èƒ½éœ€è¦å‘ä¸Šæ‰©å±•æ›´å¤šï¼‰
        } else {
            return .center       // ä¸­å¿ƒåŒºåŸŸï¼ˆå‡åŒ€æ‰©å±•ï¼‰
        }
    }
    
    /// è®¡ç®—äººè„¸ä¸“ç”¨çš„æ‰©å±•å‘é‡
    private static func calculateFaceExpansionVector(
        position: SalientPosition,
        rect: CGRect,
        imageSize: CGSize,
        targetRatio: CGFloat,
        baseFactor: CGFloat,
        type: String
    ) -> ExpansionVector {
        let currentRatio = rect.width / rect.height
        
        // äººè„¸çš„å®½é«˜æ¯”åå¥½è°ƒæ•´
        let horizontalBias: CGFloat
        let verticalBias: CGFloat
        
        if targetRatio > currentRatio {
            // éœ€è¦æ›´å®½çš„åŒºåŸŸï¼ˆåŒ…å«è‚©è†€/èº«ä½“ï¼‰
            horizontalBias = 1.4
            verticalBias = 1.0
        } else {
            // éœ€è¦æ›´é«˜çš„åŒºåŸŸï¼ˆåŒ…å«å¤´éƒ¨åˆ°èƒ¸éƒ¨ï¼‰
            horizontalBias = 1.0
            verticalBias = 1.3
        }
        
        switch position {
        case .topEdge:
            // é¡¶éƒ¨äººè„¸ï¼šä¸»è¦å‘ä¸‹æ‰©å±•ï¼ŒåŒ…å«èº«ä½“
            return ExpansionVector(
                left: baseFactor * horizontalBias,
                right: baseFactor * horizontalBias,
                top: 1.1,  // é¡¶éƒ¨å°‘é‡æ‰©å±•
                bottom: baseFactor * 1.8 * verticalBias  // åº•éƒ¨å¤§é‡æ‰©å±•
            )
            
        case .bottomEdge:
            // åº•éƒ¨äººè„¸ï¼šä¸»è¦å‘ä¸Šæ‰©å±•
            return ExpansionVector(
                left: baseFactor * horizontalBias,
                right: baseFactor * horizontalBias,
                top: baseFactor * 1.5 * verticalBias,
                bottom: 1.1  // åº•éƒ¨å°‘é‡æ‰©å±•
            )
            
        default: // .center
            // ä¸­å¿ƒäººè„¸ï¼šå‡åŒ€æ‰©å±•ï¼Œä½†åå‘åŒ…å«èº«ä½“
            return ExpansionVector(
                left: baseFactor * horizontalBias,
                right: baseFactor * horizontalBias,
                top: baseFactor * 0.8 * verticalBias,     // å¤´éƒ¨ä¸Šæ–¹é€‚åº¦æ‰©å±•
                bottom: baseFactor * 1.2 * verticalBias   // èº«ä½“ä¸‹æ–¹æ›´å¤šæ‰©å±•
            )
        }
    }
    
    // MARK: - æ˜¾è‘—æ€§æ£€æµ‹ç»“æœå¤„ç†
    
    private static func cropImageUsingSaliency(
        originalImage: UIImage,
        processedImage: UIImage,
        observation: VNSaliencyImageObservation,
        targetRatio: CGFloat,
        saliencyType: String
    ) -> UIImage? {
        let originalSize = originalImage.size
        let processedSize = processedImage.size
        print("ğŸ” SmartCropper: å¤„ç†\(saliencyType)æ˜¾è‘—æ€§ç»“æœ")
        print("   åŸå§‹å›¾ç‰‡å°ºå¯¸: \(originalSize)")
        print("   é¢„å¤„ç†å›¾ç‰‡å°ºå¯¸: \(processedSize)")
        
        // è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œç”¨äºå°†é¢„å¤„ç†å›¾ç‰‡çš„åæ ‡æ˜ å°„å›åŸå›¾
        let scaleX = originalSize.width / processedSize.width
        let scaleY = originalSize.height / processedSize.height
        
        // è·å–æ˜¾è‘—åŒºåŸŸ
        var salientRect: CGRect
        
        if let salientObjects = observation.salientObjects, !salientObjects.isEmpty {
            // åˆå¹¶æ‰€æœ‰æ˜¾è‘—å¯¹è±¡çš„è¾¹ç•Œæ¡†
            var unionRect = CGRect.zero
            for salientObject in salientObjects {
                let boundingBox = salientObject.boundingBox
                print("   æ˜¾è‘—å¯¹è±¡è¾¹ç•Œæ¡†: \(boundingBox), ç½®ä¿¡åº¦: \(salientObject.confidence)")
                
                if unionRect == .zero {
                    unionRect = boundingBox
                } else {
                    unionRect = unionRect.union(boundingBox)
                }
            }
            
            // è½¬æ¢åæ ‡ç³»ï¼ˆVisionä½¿ç”¨å·¦ä¸‹è§’ä¸ºåŸç‚¹ï¼ŒUIKitä½¿ç”¨å·¦ä¸Šè§’ä¸ºåŸç‚¹ï¼‰
            // å…ˆè½¬æ¢åˆ°é¢„å¤„ç†å›¾ç‰‡åæ ‡ç³»ï¼Œå†æ˜ å°„åˆ°åŸå›¾åæ ‡ç³»
            let processedRect = CGRect(
                x: unionRect.origin.x * processedSize.width,
                y: (1 - unionRect.origin.y - unionRect.height) * processedSize.height,
                width: unionRect.width * processedSize.width,
                height: unionRect.height * processedSize.height
            )
            
            // æ˜ å°„åˆ°åŸå›¾åæ ‡ç³»
            salientRect = CGRect(
                x: processedRect.origin.x * scaleX,
                y: processedRect.origin.y * scaleY,
                width: processedRect.width * scaleX,
                height: processedRect.height * scaleY
            )
            
            print("   åˆå¹¶åæ˜¾è‘—åŒºåŸŸ: \(salientRect)")
        } else {
            // å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°æ˜¾è‘—å¯¹è±¡ï¼Œä½¿ç”¨å›¾ç‰‡ä¸­å¿ƒåŒºåŸŸ
            print("   æœªæ£€æµ‹åˆ°æ˜¾è‘—å¯¹è±¡ï¼Œä½¿ç”¨ä¸­å¿ƒåŒºåŸŸ")
            let centerSize = min(originalSize.width, originalSize.height) * 0.8
            salientRect = CGRect(
                x: (originalSize.width - centerSize) / 2,
                y: (originalSize.height - centerSize) / 2,
                width: centerSize,
                height: centerSize
            )
        }
        
        // æ™ºèƒ½æ‰©å±•æ˜¾è‘—åŒºåŸŸï¼Œæ ¹æ®ä½ç½®å’Œç›®æ ‡å®½é«˜æ¯”åŠ¨æ€è°ƒæ•´
        let expandedRect = expandSalientRect(salientRect, in: originalSize, targetRatio: targetRatio)
        print("   æ‰©å±•ååŒºåŸŸ: \(expandedRect)")
        
        // æ ¹æ®ç›®æ ‡å®½é«˜æ¯”è°ƒæ•´è£å‰ªåŒºåŸŸ
        let finalCropRect = adjustRectForAspectRatio(expandedRect, targetRatio: targetRatio, imageSize: originalSize)
        print("   æœ€ç»ˆè£å‰ªåŒºåŸŸ: \(finalCropRect)")
        
        // æ‰§è¡Œè£å‰ªï¼ˆåŸºäºåŸå›¾ï¼‰
        guard let cgImage = originalImage.cgImage?.cropping(to: finalCropRect) else {
            print("   âŒ è£å‰ªå¤±è´¥")
            return nil
        }
        
        let croppedImage = UIImage(cgImage: cgImage, scale: originalImage.scale, orientation: originalImage.imageOrientation)
        print("   âœ… \(saliencyType)æ™ºèƒ½è£å‰ªæˆåŠŸ")
        print("   è£å‰ªåå°ºå¯¸: \(croppedImage.size)")
        
        // åº”ç”¨Widgetå°ºå¯¸é™åˆ¶
        return ImageCropper.resizeForWidget(croppedImage, targetRatio: targetRatio)
    }
    
    // MARK: - è¾…åŠ©æ–¹æ³•
    
    /// æ™ºèƒ½æ‰©å±•æ˜¾è‘—åŒºåŸŸï¼Œæ ¹æ®ä½ç½®å’Œç›®æ ‡å®½é«˜æ¯”åŠ¨æ€è°ƒæ•´
    private static func expandSalientRect(
        _ rect: CGRect,
        in imageSize: CGSize,
        targetRatio: CGFloat
    ) -> CGRect {
        // åˆ†ææ˜¾è‘—åŒºåŸŸçš„ä½ç½®ç‰¹å¾
        let position = analyzeSalientPosition(rect, in: imageSize)
        
        // è®¡ç®—åŸºç¡€æ‰©å±•å› å­ï¼ˆæ ¹æ®æ˜¾è‘—åŒºåŸŸå æ¯”ï¼‰
        let areaRatio = (rect.width * rect.height) / (imageSize.width * imageSize.height)
        let baseExpansionFactor = calculateBaseExpansionFactor(areaRatio: areaRatio)
        
        // æ ¹æ®ä½ç½®å’Œç›®æ ‡å®½é«˜æ¯”è®¡ç®—æ–¹å‘æ€§æ‰©å±•
        let expansionVector = calculateExpansionVector(
            position: position,
            rect: rect,
            imageSize: imageSize,
            targetRatio: targetRatio,
            baseFactor: baseExpansionFactor
        )
        
        // åº”ç”¨æ‰©å±•å¹¶ç¡®ä¿è¾¹ç•Œçº¦æŸ
        return applyExpansionWithBounds(
            rect: rect,
            expansionVector: expansionVector,
            imageSize: imageSize
        )
    }
    
    /// åˆ†ææ˜¾è‘—åŒºåŸŸåœ¨å›¾ç‰‡ä¸­çš„ä½ç½®ç±»å‹
    private static func analyzeSalientPosition(_ rect: CGRect, in imageSize: CGSize) -> SalientPosition {
        // å›¾ç‰‡ä¸­å¿ƒç‚¹åæ ‡
        // centerY æœªä½¿ç”¨ï¼Œç§»é™¤
        let rectCenterX = rect.midX
        let rectCenterY = rect.midY
        
        // å®šä¹‰è¾¹ç•Œé˜ˆå€¼ï¼ˆè·ç¦»è¾¹ç¼˜çš„æ¯”ä¾‹ï¼‰
        let edgeThreshold: CGFloat = 0.15 // 15%çš„è¾¹ç¼˜åŒºåŸŸ
        // cornerThreshold æœªä½¿ç”¨ï¼Œç§»é™¤
        
        let leftEdge = imageSize.width * edgeThreshold
        let rightEdge = imageSize.width * (1 - edgeThreshold)
        let topEdge = imageSize.height * edgeThreshold
        let bottomEdge = imageSize.height * (1 - edgeThreshold)
        
        // åˆ¤æ–­æ˜¯å¦åœ¨è§’è½
        if (rectCenterX < leftEdge && rectCenterY < topEdge) {
            return .topLeft
        } else if (rectCenterX > rightEdge && rectCenterY < topEdge) {
            return .topRight
        } else if (rectCenterX < leftEdge && rectCenterY > bottomEdge) {
            return .bottomLeft
        } else if (rectCenterX > rightEdge && rectCenterY > bottomEdge) {
            return .bottomRight
        }
        // åˆ¤æ–­æ˜¯å¦åœ¨è¾¹ç¼˜
        else if rectCenterX < leftEdge {
            return .leftEdge
        } else if rectCenterX > rightEdge {
            return .rightEdge
        } else if rectCenterY < topEdge {
            return .topEdge
        } else if rectCenterY > bottomEdge {
            return .bottomEdge
        }
        // å¦åˆ™åœ¨ä¸­å¿ƒåŒºåŸŸ
        else {
            return .center
        }
    }
    
    /// æ ¹æ®æ˜¾è‘—åŒºåŸŸå æ¯”è®¡ç®—åŸºç¡€æ‰©å±•å› å­
    private static func calculateBaseExpansionFactor(areaRatio: CGFloat) -> CGFloat {
        switch areaRatio {
        case 0.7...1.0:   // æ˜¾è‘—åŒºåŸŸå¾ˆå¤§ï¼ˆ70%ä»¥ä¸Šï¼‰
            return 1.05   // åªéœ€è¦å¾ˆå°‘æ‰©å±•
        case 0.4...0.7:   // æ˜¾è‘—åŒºåŸŸä¸­ç­‰ï¼ˆ40%-70%ï¼‰
            return 1.15   // é€‚ä¸­æ‰©å±•
        case 0.2...0.4:   // æ˜¾è‘—åŒºåŸŸè¾ƒå°ï¼ˆ20%-40%ï¼‰
            return 1.3    // è¾ƒå¤šæ‰©å±•
        default:          // æ˜¾è‘—åŒºåŸŸå¾ˆå°ï¼ˆ<20%ï¼‰
            return 1.5    // å¤§é‡æ‰©å±•ä»¥åŒ…å«æ›´å¤šä¸Šä¸‹æ–‡
        }
    }
    
    /// è®¡ç®—æ–¹å‘æ€§æ‰©å±•å‘é‡
    private static func calculateExpansionVector(
        position: SalientPosition,
        rect: CGRect,
        imageSize: CGSize,
        targetRatio: CGFloat,
        baseFactor: CGFloat
    ) -> ExpansionVector {
        let currentRatio = rect.width / rect.height
        
        // æ ¹æ®ç›®æ ‡å®½é«˜æ¯”è°ƒæ•´æ‰©å±•åå¥½
        let horizontalBias: CGFloat
        let verticalBias: CGFloat
        
        if targetRatio > currentRatio {
            // éœ€è¦æ›´å®½çš„åŒºåŸŸ
            horizontalBias = 1.2
            verticalBias = 0.9
        } else if targetRatio < currentRatio {
            // éœ€è¦æ›´é«˜çš„åŒºåŸŸ
            horizontalBias = 0.9
            verticalBias = 1.2
        } else {
            // æ¯”ä¾‹å·²ç»åˆé€‚
            horizontalBias = 1.0
            verticalBias = 1.0
        }
        
        // æ ¹æ®ä½ç½®è®¡ç®—æ–¹å‘æ€§æ‰©å±•
        switch position {
        case .center:
            // ä¸­å¿ƒä½ç½®ï¼šå‡åŒ€å‘å››å‘¨æ‰©å±•
            return ExpansionVector(
                left: baseFactor * horizontalBias,
                right: baseFactor * horizontalBias,
                top: baseFactor * verticalBias,
                bottom: baseFactor * verticalBias
            )
            
        case .leftEdge:
            // å·¦è¾¹ç¼˜ï¼šä¸»è¦å‘å³æ‰©å±•
            return ExpansionVector(
                left: 1.0,
                right: baseFactor * 1.5 * horizontalBias,
                top: baseFactor * verticalBias,
                bottom: baseFactor * verticalBias
            )
            
        case .rightEdge:
            // å³è¾¹ç¼˜ï¼šä¸»è¦å‘å·¦æ‰©å±•
            return ExpansionVector(
                left: baseFactor * 1.5 * horizontalBias,
                right: 1.0,
                top: baseFactor * verticalBias,
                bottom: baseFactor * verticalBias
            )
            
        case .topEdge:
            // ä¸Šè¾¹ç¼˜ï¼šä¸»è¦å‘ä¸‹æ‰©å±•
            return ExpansionVector(
                left: baseFactor * horizontalBias,
                right: baseFactor * horizontalBias,
                top: 1.0,
                bottom: baseFactor * 1.5 * verticalBias
            )
            
        case .bottomEdge:
            // ä¸‹è¾¹ç¼˜ï¼šä¸»è¦å‘ä¸Šæ‰©å±•
            return ExpansionVector(
                left: baseFactor * horizontalBias,
                right: baseFactor * horizontalBias,
                top: baseFactor * 1.5 * verticalBias,
                bottom: 1.0
            )
            
        case .topLeft:
            // å·¦ä¸Šè§’ï¼šå‘å³ä¸‹æ‰©å±•
            return ExpansionVector(
                left: 1.0,
                right: baseFactor * 1.8 * horizontalBias,
                top: 1.0,
                bottom: baseFactor * 1.8 * verticalBias
            )
            
        case .topRight:
            // å³ä¸Šè§’ï¼šå‘å·¦ä¸‹æ‰©å±•
            return ExpansionVector(
                left: baseFactor * 1.8 * horizontalBias,
                right: 1.0,
                top: 1.0,
                bottom: baseFactor * 1.8 * verticalBias
            )
            
        case .bottomLeft:
            // å·¦ä¸‹è§’ï¼šå‘å³ä¸Šæ‰©å±•
            return ExpansionVector(
                left: 1.0,
                right: baseFactor * 1.8 * horizontalBias,
                top: baseFactor * 1.8 * verticalBias,
                bottom: 1.0
            )
            
        case .bottomRight:
            // å³ä¸‹è§’ï¼šå‘å·¦ä¸Šæ‰©å±•
            return ExpansionVector(
                left: baseFactor * 1.8 * horizontalBias,
                right: 1.0,
                top: baseFactor * 1.8 * verticalBias,
                bottom: 1.0
            )
        }
    }
    
    /// åº”ç”¨æ‰©å±•å‘é‡å¹¶ç¡®ä¿è¾¹ç•Œçº¦æŸ
    private static func applyExpansionWithBounds(
        rect: CGRect,
        expansionVector: ExpansionVector,
        imageSize: CGSize
    ) -> CGRect {
        // è®¡ç®—æ‰©å±•åçš„è¾¹ç•Œ
        let leftExpansion = rect.width * (expansionVector.left - 1) / 2
        let rightExpansion = rect.width * (expansionVector.right - 1) / 2
        let topExpansion = rect.height * (expansionVector.top - 1) / 2
        let bottomExpansion = rect.height * (expansionVector.bottom - 1) / 2
        
        var expandedRect = CGRect(
            x: rect.origin.x - leftExpansion,
            y: rect.origin.y - topExpansion,
            width: rect.width + leftExpansion + rightExpansion,
            height: rect.height + topExpansion + bottomExpansion
        )
        
        // è¾¹ç•Œçº¦æŸå’Œæ™ºèƒ½è°ƒæ•´
        if expandedRect.minX < 0 {
            let overflow = -expandedRect.minX
            expandedRect.origin.x = 0
            expandedRect.size.width = min(expandedRect.width + overflow, imageSize.width)
        }
        
        if expandedRect.minY < 0 {
            let overflow = -expandedRect.minY
            expandedRect.origin.y = 0
            expandedRect.size.height = min(expandedRect.height + overflow, imageSize.height)
        }
        
        if expandedRect.maxX > imageSize.width {
            let overflow = expandedRect.maxX - imageSize.width
            expandedRect.origin.x = max(0, expandedRect.origin.x - overflow)
            expandedRect.size.width = imageSize.width - expandedRect.origin.x
        }
        
        if expandedRect.maxY > imageSize.height {
            let overflow = expandedRect.maxY - imageSize.height
            expandedRect.origin.y = max(0, expandedRect.origin.y - overflow)
            expandedRect.size.height = imageSize.height - expandedRect.origin.y
        }
        
        return expandedRect
    }
    
    /// æ ¹æ®ç›®æ ‡å®½é«˜æ¯”è°ƒæ•´çŸ©å½¢åŒºåŸŸ
    private static func adjustRectForAspectRatio(
        _ rect: CGRect,
        targetRatio: CGFloat,
        imageSize: CGSize
    ) -> CGRect {
        let currentRatio = rect.width / rect.height
        
        var adjustedRect = rect
        
        if currentRatio > targetRatio {
            // å½“å‰åŒºåŸŸå¤ªå®½ï¼Œéœ€è¦å‡å°‘å®½åº¦æˆ–å¢åŠ é«˜åº¦
            let targetWidth = rect.height * targetRatio
            adjustedRect.size.width = targetWidth
            adjustedRect.origin.x = rect.midX - targetWidth / 2
        } else if currentRatio < targetRatio {
            // å½“å‰åŒºåŸŸå¤ªé«˜ï¼Œéœ€è¦å‡å°‘é«˜åº¦æˆ–å¢åŠ å®½åº¦
            let targetHeight = rect.width / targetRatio
            adjustedRect.size.height = targetHeight
            adjustedRect.origin.y = rect.midY - targetHeight / 2
        }
        
        // ç¡®ä¿è°ƒæ•´åçš„åŒºåŸŸä¸è¶…å‡ºå›¾ç‰‡è¾¹ç•Œ
        adjustedRect.origin.x = max(0, min(adjustedRect.origin.x, imageSize.width - adjustedRect.width))
        adjustedRect.origin.y = max(0, min(adjustedRect.origin.y, imageSize.height - adjustedRect.height))
        adjustedRect.size.width = min(adjustedRect.size.width, imageSize.width - adjustedRect.origin.x)
        adjustedRect.size.height = min(adjustedRect.size.height, imageSize.height - adjustedRect.origin.y)
        
        return adjustedRect
    }
}